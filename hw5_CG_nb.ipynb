{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('responses2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of non-integer columns:\n",
      "- Smoking\n",
      "- Alcohol\n",
      "- Punctuality\n",
      "- Lying\n",
      "- Internet usage\n",
      "- Gender\n",
      "- Left - right handed\n",
      "- Education\n",
      "- Only child\n",
      "- Village - town\n",
      "- House - block of flats\n"
     ]
    }
   ],
   "source": [
    "print('List of non-integer columns:')\n",
    "for id,dtyp in df.dtypes.iteritems():\n",
    "    if dtyp=='object':\n",
    "        print('-',id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for id,val in df.isnull().sum().iteritems():\n",
    "#    if val>(0.2 * len(df)):\n",
    "#        print(id,val)\n",
    "#No columns with huge number of missing values\n",
    "\n",
    "#print(\"Columns with largest missing value count\")\n",
    "#for id,val in df.isnull().sum().iteritems():\n",
    "#    if val>(0.01 * len(df)):\n",
    "#        print(id,'\\t\\t',val)\n",
    "        \n",
    "for col in list(df):\n",
    "    df[col].fillna(df[col].mode()[0], inplace = True)  \n",
    "    \n",
    "for id,val in df.isnull().sum().iteritems():\n",
    "    if val>0:\n",
    "        print(id,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "categoricalFeatures = []\n",
    "for col in [id for id,dtyp in df.dtypes.iteritems() if dtyp=='object']:\n",
    "    categoricalFeatures.append(col)\n",
    "    df[col] = le.fit_transform(df[col].astype('str'))\n",
    "    #print(col,\"\\n\",df[col][:5])\n",
    "#df = df.drop(columns=categoricalFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[categoricalFeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF shape:  (1010, 150)\n",
      "DF2 shape:  (1010, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"DF shape: \",df.shape)\n",
    "print(\"DF2 shape: \",df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df.drop(categoricalFeatures, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF shape:  (1010, 173)\n"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "#for col in categoricalFeatures:\n",
    "df = df.join(pd.DataFrame(ohe.fit_transform(df2).toarray()))\n",
    "print(\"DF shape: \",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp = df['Empathy']\n",
    "df = df.drop('Empathy',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
    "rescaledX = MinMaxScaler(feature_range=(0, 1)).fit_transform(df)\n",
    "standardizedX = StandardScaler().fit_transform(rescaledX)\n",
    "normalizedX = Normalizer().fit_transform(standardizedX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "newdf = Normalizer().fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "dtree = DecisionTreeClassifier(max_depth=2)\n",
    "knn = KNeighborsClassifier()\n",
    "#svc = SVC(kernel='poly',degree=2, gamma = 1.2, C=1.2, coef0=1)\n",
    "svc = LinearSVC(dual=False)#dual=False, C=2)\n",
    "gnb = GaussianNB()\n",
    "mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = list(df)\n",
    "t.remove('Empathy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, emp, test_size=0.2,random_state = 0)#(df[t], df['Empathy'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.2,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.376543209877\n"
     ]
    }
   ],
   "source": [
    "gnb.fit(X_train,y_train)\n",
    "print(gnb.score(X_dev,y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40740740740740738"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'C':[0.01, 0.1, 2, 4, 8, 10], 'degree':[1,2,3,4,5,6]}\n",
    "#parameters = {'dual':(False, True), 'C':[0.001, 0.01, 0.1, 1, 2, 3, 4, 5, 10]}\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2, 'degree': 1}"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3888888888888889"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accSum = []\n",
    "#for i in range(10):\n",
    "svc.fit(X_train,y_train)\n",
    "#accSum.append(\n",
    "svc.score(X_dev,y_dev)#)    \n",
    "#np.mean(accSum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39506172839506171"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accSum = []\n",
    "#for i in range(10):\n",
    "dtree.fit(X_train,y_train)\n",
    "#accSum.append(\n",
    "dtree.score(X_dev,y_dev)#)\n",
    "#np.mean(accSum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chinm\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev:  0.393209876543\n",
      "Test:  0.356435643564\n"
     ]
    }
   ],
   "source": [
    "accSum = []\n",
    "for i in range(10):\n",
    "    mlp.fit(X_train,y_train)\n",
    "    accSum.append(mlp.score(X_dev,y_dev))\n",
    "print(\"Dev: \",np.mean(accSum))\n",
    "print(\"Test: \",mlp.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3888888888888889"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=9,max_depth=6, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 5\n",
      "RandomForest score on dev 0.333333333333\n",
      "\n",
      "1 7\n",
      "RandomForest score on dev 0.37037037037\n",
      "\n",
      "2 5\n",
      "RandomForest score on dev 0.376543209877\n",
      "\n",
      "3 6\n",
      "RandomForest score on dev 0.395061728395\n",
      "\n",
      "5 5\n",
      "RandomForest score on dev 0.401234567901\n",
      "\n",
      "9 6\n",
      "RandomForest score on dev 0.413580246914\n",
      "\n",
      "11 7\n",
      "RandomForest score on dev 0.425925925926\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for nest in range(1,13):\n",
    "    for dep in range(5,11):\n",
    "        rfc = RandomForestClassifier(n_estimators=nest,max_depth=dep, random_state=0)\n",
    "        rfc.fit(X_train, y_train)\n",
    "        devScore = rfc.score(X_dev, y_dev)\n",
    "        if devScore > acc:\n",
    "            acc = devScore\n",
    "            print()\n",
    "            print(nest,dep)\n",
    "            print(\"RandomForest score on dev\",rfc.score(X_dev, y_dev))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "accList=[]\n",
    "bestAcc = 0.1\n",
    "bestK = 1\n",
    "for i in range(5):\n",
    "    for k in range(1,170,10):\n",
    "        \n",
    "        X_new = SelectKBest(chi2, k).fit_transform(X_dev, y_dev)\n",
    "        svcTuned.fit()\n",
    "        \n",
    "        #nowAcc = np.mean(cross_val_score(svc, X_new, df['Empathy'],cv=10))\n",
    "        if nowAcc>bestAcc:\n",
    "            bestAcc = nowAcc\n",
    "            #bestK = k\n",
    "    accList.append(bestAcc)\n",
    "    print(bestAcc)\n",
    "        \n",
    "#print('k=',bestK)\n",
    "print('Accuracy of baseline=',np.mean(accList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbesht = SelectKBest(chi2,20)\n",
    "X_new = kbesht.fit_transform(X_dev, y_dev)\n",
    "relevantCols = []\n",
    "for col in kbesht.get_support(indices=True):\n",
    "    relevantCols.append(df.columns[col])\n",
    "\n",
    "#print(relevantCols)    \n",
    "\n",
    "#X_train[relevantCols]\n",
    "X_train = X_train[relevantCols]\n",
    "X_dev = X_dev[relevantCols]\n",
    "X_test = X_test[relevantCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest score on dev 0.376543209877\n",
      "RandomForest score on test 0.371287128713\n"
     ]
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, 11).fit_transform(X_train, y_train)\n",
    "relevantCols = []\n",
    "for col in kbesht.get_support(indices=True):\n",
    "    relevantCols.append(df.columns[col])\n",
    "rfc = RandomForestClassifier(n_estimators=10,max_depth=9, random_state=0)\n",
    "rfc.fit(X_train[relevantCols], y_train)\n",
    "print(\"RandomForest score on dev\",rfc.score(X_dev[relevantCols], y_dev))\n",
    "print(\"RandomForest score on test\",rfc.score(X_test[relevantCols], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev:  0.382716049383\n",
      "Test:  0.366336633663\n"
     ]
    }
   ],
   "source": [
    "svcTuned = LinearSVC(dual=False)\n",
    "accSum = []\n",
    "for i in range(10):\n",
    "    svcTuned.fit(X_train,y_train)\n",
    "    accSum.append(svcTuned.score(X_dev,y_dev))    \n",
    "print(\"Dev: \",np.mean(accSum))\n",
    "print(\"Test: \",svcTuned.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev:  0.444444444444\n",
      "Test:  0.356435643564\n"
     ]
    }
   ],
   "source": [
    "dtreeTuned = DecisionTreeClassifier(max_depth=2)\n",
    "accSum = []\n",
    "for i in range(10):\n",
    "    dtreeTuned.fit(X_train,y_train)\n",
    "    accSum.append(dtreeTuned.score(X_dev,y_dev))\n",
    "print(\"Dev: \",np.mean(accSum))\n",
    "print(\"Test: \",dtreeTuned.score(X_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
